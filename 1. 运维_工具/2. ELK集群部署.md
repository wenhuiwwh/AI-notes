# ELK平台部署说明书

## 1. 部署说明

### 1.1 部署环境

| 服务器IP   | IP主机名 | 角色     | 部署软件                                                     |
| ---------- | -------- | -------- | ------------------------------------------------------------ |
| 10.5.4.147 | node147  | 主节点   | JDK 1.8<br />logstash-6.2.3<br />elasticsearch-6.2.3<br />node-v10.16.0-linux-x6<br />elasticsearch-head-master |
| 10.5.4.148 | node148  | ES辅节点 | JDK 1.8<br />logstash-6.2.3<br />elasticsearch-6.2.3<br />node-v10.16.0-linux-x6<br />elasticsearch-head-master |
| 10.5.4.149 | node149  | ES辅节点 | JDK 1.8<br />logstash-6.2.3<br />elasticsearch-6.2.3<br />node-v10.16.0-linux-x6<br />elasticsearch-head-master |

### 1.2 部署准备

#### 1.2.1 设置主机名

1、登陆 10.5.4.147 服务器，更改 `/etc/sysconfig` 下的 `network` 文件，在提示符下输入`vi /etc/sysconfig/network` 然后将HOSTNAME后面的值改为想要设置的主机名。（例如：node147）

其它2台机子同理配置

2、登录 10.5.4.147 服务器，更改 /etc 下的 hosts 文件，在提示符下输入 `vi/etc/hosts`，增加以下内容：

```tex
10.5.4.147   node147
10.5.4.148   node148
10.5.4.149   node149
```

其它2台机子同理配置

#### 1.1.2 添加用户

以root身份登录 10.5.4.147 服务器，执行 useradd，添加用户，elk1，设置密码：123456，如下：

```shell
useradd -m elk1
passwd 123456
```

查看用户信息

```shell
cat /etc/passwd
```

其它2台机子同理配置



## 2. 组件部署

### 2.1 部署JDK

组件以root登录后部署，三台服务器都是如下操作：

 ![1567670765468.png](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrbyebt6rj20e10210sl.jpg)

### 2.2 部署Logstash

**在3台节点部署logstash**

1、下载logstash-6.2.3.tar.gz安装包并上传到自定义的 `/opt/cloudera/parcels/software`目录下

2、解压logstash-6.2.3.tar.gz

```shell
tar –zxvf logstash-6.2.3.tar.gz –C /opt/cloudera/parcels/model
```

3、进入 `/opt/cloudera/parcels/model/logstash-6.2.3`，新建conf文件夹，写配置文件验证安装成功

```shell
mkdir conf
cd conf
vi test.conf
```

4、录入以下内容：

```shell
input { 
    stdin { } 
} 
output { 
	stdout { 
	codec => rubydebug 
	}
 }
```

5、执行`./bin/logstash -f  ./conf/test.conf`

![1567671399657.png](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrbzwl20zj212f02it8y.jpg)

如上图所示，则安装成功

> 如果服务器上同时存在jdk1.7和jdk1.8时，因为logstash启动依赖jdk1.8,所以在启动时指定依赖的jdk,需要这样做： 在logstash 和logstash.lib.sh 里面加上 export JAVA1.8_HOME 就可以了。

**配置文件的验证**

要验证配置，请运行以下命令：

```bash
bin/logstash -f first-pipeline.conf -t
```

`-t`：选项解析您的配置文件并报告任何错误。如果配置文件通过配置测试，请使用以下命令启动Logstash：

```bash
bin/logstash -f first-pipeline.conf --config.reload.automatic
```

`--config.reload.automatic` 选项启用自动配置重新加载，因此每次修改配置文件时都不必停止并重新启动Logstash。

> 当Logstash启动时，可能会看到有关Logstash的一条或多条警告消息，而忽略了pipelinelines.yml文件。 可以放心地忽略此警告。 pipelines.yml文件用于在单个Logstash实例中运行多个管道。 对于这里显示的示例，正在运行一个管道

### 2.3 部署Elasticsearch

<font color='red'>注意：安装时，用root用户可以，但启动的时候必须是普通用户。</font>

#### 2.3.1 部署node147节点

1、上传elasticsearch-6.2.3.tar.gz安装包到 `/opt/cloudera/parcels/software` 目录下

2、解压elasticsearch-6.2.3.tar.gz安装包

```
tar –zxvf elasticsearch-6.2.3.tar.gz –C /usr
```

3、配置elasticsearch.yml，切换到`/usr/elasticsearch-6.2.3/config` 目录下

```shell
cluster.name : my-application
node.name : node147
path.data: /usr/elasticsearch-6.2.3/data
path.logs: /usr/elasticsearch-6.2.3/logs
network.host : node147
http.port : 9200
discovery.zen.ping.unicast.hosts : ["node147", "node148","node149"]
discovery.zen.minimum_master_nodes: 2
node.master: true
node.data: true
http.cors.enabled : true
http.cors.allow-origin : "*"
```

4、配置环境变量

```shell
cd /etc/profile.d
vi es.sh
export ELASTICSEARCH_HOME=/usr/elasticsearch-6.2.3
export PATH=$PATH:$ELASTICSEARCH_HOME/bin
```

5、上传node-v10.16.0-linux-x64， elasticsearch-head-master，里面都是下载好的nodejs和grunt，可以直接使用，并配置环境变量。

```shell
cd /etc/profile.d
vi node.sh
export NODE_HOME=/usr/nodejs/node-v10.16.0-linux-x64
export PATH=$NODE_HOME/bin:$PATH
```

执行`source /etc/profile`

```shell
vi es_head.sh
export ES_HEAD=/opt/cloudera/parcels/model/elasticsearch-head-master
export PATH=$PATH:$ES_HEAD/node_modules/grunt/bin
```

执行`source /etc/profile`

**多个jdk解决方法**

若启动es需指定jdk，则这样做

执行`vim bin/elasticsearch`, 添加如下代码：

>```shell
>export ES_JAVA_HOME =/usr/java/jdk1.8.0_144
>export PATH=$JAVA_HOME/bin:$PATH
>if [ -x "$ ES_JAVA_HOME " ];
>   then
>         JAVA=$ES_JAVA_HOME/bin/java
>   else
>         JAVA=`which java`
>   Fi
>     ```
>   
执行 `vim elasticsearch-plugin`
>   
>   ```shell
>export ES_JAVA_HOME=/usr/java/jdk1.8.0_144
>export PATH=$ES_JAVA_HOME/bin:$PATH
>if [ -x "$ES_JAVA_HOME/bin/java" ]; 
>   then
>     JAVA=$ES_JAVA_HOME/bin/java
>   else
>     JAVA=`which java`
>   fi
>     ```

#### 2.3.2 部署node148节点

1、将配置好的elasticsearch文件夹拷贝到另一台服务器上node148

```shell
scp –r /opt/cloudera/parcels/model/elasticsearch-6.2.3 root@10.5.4.148: /opt/cloudera/parcels/model
```

2、修改以下几项

```shell
node.name : node148
network.host : node148
```

3、部署和配置 node-v10.16.0-linux-x64, elasticsearch-head-master 同node147

#### 2.3.3 部署node149节点

1、将配置好的elasticsearch文件夹拷贝到另一台服务器上node149

```shell
scp –r /opt/cloudera/parcels/model/elasticsearch-6.2.3 root@10.5.4.148: /opt/cloudera/parcels/model
```

2、修改以下几项

```shell
node.name : node149
network.host : node149
```

3、部署和配置 node-v10.16.0-linux-x64, elasticsearch-head-master 同node147

### 2.4 启动服务和测试

在node147、node148和node149节点上分别执行以下操作

**1. 启动elasticsearch**

查找grunt所在目录

```shell
find / -name grunt
```

![1567676281995.png](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrc0mpea5j20ls02m3yi.jpg)

切换目录

```shell
cd /opt/cloudera/parcels/model/elasticsearch-head-master/node_modules/grunt/bin/
```

前台启动：`grunt server`

 ![1567676395390.png](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrc1868psj20fl02b3yd.jpg)

**2. 启动grunt**

```shell
// 后台启动
nohup grunt server 2>&1 &
```

出现如下图所示，则安装成功

 ![1567676612843.png](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrc24vjloj20ds01k3yb.jpg)

**访问 http://10.5.4.147:9100  和 http://10.5.4.148:9100 和 http://10.5.4.149:9100**

![1567676808345.png](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrc2t6v69j20r10fd0u9.jpg)

### 2.4 部署Kibana

1、下载kibana-6.2.3-linux-x86_64.tar.gz 安装包到自定义/etc/software的目录下

2、解压缩

```shell
tar –zxvf kibana-6.2.3-linux-x86_64.tar.gz –C /usr/
```

3、修改kibana.yml配置文件

```shell
vi /usr/kibana-6.2.3-linux-x86_64/config/kibana.yml
server.port: 5601
server.host: 10.5.4.147
server.name: node111a147
elasticsearch.url: "http://10.5.4.149:9200"
pid.file: /usr/kibana-6.2.3-linux-x86_64/kibana.pid
```

4、配置环境变量

```shell
vi /etc/profile.d/kibana.sh
export KIBANA_HOME=/usr/kibana-6.2.3-linux-x86_64
export PATH=$PATH:$KIBANA_HOME/bin
```

键入 `source /etc/proflie `使其生效

5、启动kibana

* **前台启动**：kibana
* **后台启动**：`nohup kibana > /usr/kibana-6.2.3-linux-x86_64/runlog/kibana.log 2>&1 &`
* 停止kibana：可以通过`netstat -anltp|grep 5601` 查找端口
* 检查配置文件是否出错：`./bin/logstash -f ./conf/txtInput.conf -t`

6、在浏览器中输入：http://10.5.4.17:5601,出现如下图所示，则成功

![1567679151992-1567760483402.png](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrc3yw1o6j20se0cijsn.jpg)



## 3. 开机启动

### 3.1 配置Elasticsearch

```shell
cd /etc/init.d
touch elasticsearch
chmod +x elasticsearch
vi elasticsearch
```

输入以下内容：

```
#!bin/bash  
# chkconfig:   2345 21  89  
# description:  elasticsearch  
  
# JAVA_HOME=/usr/java/latest  
ES_HOME=/opt/cloudera/parcels/model/elasticsearch-6.2.3
case $1 in  
            start) su elasticsearch $ES_HOME/bin/elasticsearch &;;  
            *)  echo "require start"  ;;  
esac
```

### 3.2 配置Logstash

```shell
cd /etc/init.d
touch logstash
chmod +x logstash
vi logstash
```

 输入以下内容：

```shell
#!/bin/bash  
	  	
	   # chkconfig:   2345 50  50  
	   # description:  logstash  
	 	
LS_HOME=/opt/cloudera/parcels/model/logstash-6.2.3
	   case $1 in  
	        start) nohup $LS_HOME/bin/logstash -f $LS_HOME/conf/kafkaInput.conf >/dev/null2 2>&1 &;;  

	        *) echo "require start";;  
	   esac  

```

### 3.3 配置Kibana

```shell
cd /etc/init.d
touch kibana
chmod +x kibana
vi kibana
```

输入以下内容：

```shell
 #!/bin/bash  
  
# chkconfig:   2345 98  02  
# description:  kibana  
  
KIBANA_HOME=/usr/kibana-6.2.3-linux-x86_64/
case $1 in  
                   start) nohup $KIBANA_HOME/bin/kibana >/dev/null 2>&1 &;;  
             *) echo "require start";;  
esac  

```

### 3.3 设置服务自启动

```shell
chkconfig --add elasticsearch
chkconfig --add logstash
chkconfig --add kibana
```

输入  `chkconfig --list`，当发现一下服务存在时，说明自启动配置成功：

 ![1567731295613.png](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrc4gzktlj20fq027jr9.jpg)

注意：当开机启动logstash没有运行时，需要加 `systemctl start logstash`，再次开机启动，就会出现logstash的运行线程



## 4. 自动报警Sentinl

### 4.1 说明

在 Kibana 中部署 Sentinl，通过在 Logstash 配置监测多个目录多个文件的异常信息到 Elasticsearch 中，再通过在 Sentinl 配置监测 Elasticsearch 中的收集的异常信息索引的信息，在相应的时间监测到异常信息触发报警，接着将报警信息通过 Webook 方式推给 Spring Boot 的接口，然后对返回的信息进行标准格式的处理，最后将报警信息推给企业微信进行报警。

### 4.2 部署Sentinl

1、下载与 kibana 6.2.3 对应的 sentinl 6.2.3 版本

```shell
wget https://github.com/sirensolutions/sentinl/releases/download/tag-6.2.3-3/sentinl-v6.2.3.zip
```

若没有连网，可以直接上传文件

2、安装 sentinl 6.2.3

```shell
./bin/kibana-plugin install file:///tmp/sentinl-v6.2.3.zip
```

如果安装过程中出现 `Plugin installation complete` 信息，则表示安装成功

3、查看 kibana界面中的 sentinl

![1567733063813.png](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrc4xacn2j20q60aft8y.jpg)

### 4.3 报警实现

#### 4.3.1 说明

 测试 “ logstash 在前1分钟内收集到的异常信息条数大于等于1次” 就告警。

#### 4.3.2 配置Logstash

注意：这个可以在集群的每台服务器部署的 logstash 中配置，这样的话可以监测多台服务器多个目录下的多个文件的异常信息，但是这里只部署了一台作为例子，如果想部署多个，就在多台服务器上执行相同的配置文件运行命令就可以，<font color='blue'>这里的配置过程与第二节中的Logstash配置完全一样，只需更改配置文件即可</font>。

```json
input{
 file{
  path=>"/opt/model/logfile/spark/*.log" //监测的路径
  start_position=>"end"                  //监测的位置，从最新的日志内容开始监测
  type=>"spark"                          //整个file监测的类型
  sincedb_path=>"/dev/null"              //存放offset的路径
	 }
  file{
  path=>"/opt/model/logfile/storm/*.log"
  start_position=>"end"
  type=>"storm"
  sincedb_path=>"/dev/null"
 	}
}
//解决时差为8小时的问题
filter {
    date {
    match => ["message","UNIX_MS"]
    target => "@timestamp"   
 	 }
 ruby { 
   code => "event.set('timestamp', event.get('@timestamp').time.localtime + 8*60*60)" 
 	}
 ruby {
   code => "event.set('@timestamp',event.get('timestamp'))"
	 }
 mutate {
   remove_field => ["timestamp"]   //移除timestamp字段
   remove_field=>["tags"]          //移除tags字段
	 }
//将多行的异常信息合并成一行
    multiline {
        pattern => "^\s" 
        what => "previous"
    } 
//过滤出异常信息包含ERROR和EXCEPTION的信息
    if [message] !~ "ERROR" and [message] !~ "EXCEPTION" {
       drop {}
    }
}
output{
elasticsearch{
       hosts => ["gsafety1:9200","gsafety2:9200","gsafety3:9200"] //hosts
       index => "runlog-%{+YYYY.MM.dd}" //输出到的index名称
       document_type => "runlog"        //索引文档的类型
	}
}
```

#### 4.3.3 配置Sentinl

1、在 kibana 界面上配置 sentinl，点击右上角 new 创建 watchers

  ![wps3.jpg](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrc5mgfd0j20fn03u0t3.jpg)

2、点击 +watcher创建新的Watcher。

 ![wps4.jpg](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrc63w6hdj20fd04h74r.jpg)

3、填写General页面内容， title是watcher的名称，Schedule是执行周期

 ![wps5.jpg](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrc6icgogj20fe06g3z5.jpg)

4、填写input页面内容， body 里面填写ES查询语句，可根据具体业务编写相应的查询语句。

 ![wps6.jpg](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrc78rnyrj20fe05ijs0.jpg)
    
```json
{
  "search": {
    "request": {
      "index": [
        "runlog-*"
      ],
      "body": {
        "query": {
          "bool": {
            "must": [
              {
                "query_string": {
                  "default_field": "message.keyword",
                  "query": "*ERROR*"
                }
              },
              {
                "range": {
                  "@timestamp": {
                    "gte": "now-1000m", //如果监测是前三十分钟，gte和
                    "lt": "now+500m"   //lt各自减去30分钟就行
                  }
                }
              }
            ],
            "must_not": [],
            "should": []
          }
        },
        "from": 0,
        "size": 10,
        "sort": [],
        "aggs": {}
      }
    }
  }
}
```

5、填写Condition页面内容， payload.hits.total >= 1 （当查询结果数大于等于1时，触发Actions），可以自己制定条件。

 ![wps7.jpg](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrcgbq670j20ff058jrx.jpg)

6、Transform 可对input查询的结果做一些处理，此处没有使用，可以不填写。

 ![wps8.jpg](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrcgvmil3j20fe05xwey.jpg)

7、填写Actions页面内容，Actions包括webhook，email，email html，report，slack，console，此处介绍webhook。

 ![wps9.jpg](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrch86m3nj20ff03smxm.jpg)

8、使用webhook发rest请求，可以选择 get或post两种方式。

 ![wps10.jpg](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrchl11c1j20fe0823zq.jpg)

Body里面的内容：

```shell
{
"errorCount":"{{payload.hits.total}}","msgs":"{{#payload.hits.hits}}{{_
source.@timestamp}}——{{_source.host}}——{{_source.type}}——{{_
source.path}}——{{_source.message}}\n{{/payload.hits.hits}}","level":"4"
}
```

Headers里面的内容：

```shell
{
  "Content-Type": "application/yaml"
}
```

9、添加message内容，选中enable按钮

 ![wps11.jpg](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrci2dzxrj20ff06egmi.jpg)

10、填好对应数据之后，点击右上角的Save按钮

 ![wps12.jpg](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrcigw969j20fe0593z5.jpg)

### 4.4 在服务器部署Sprint Boot

将Spring Boot工程打包上传到集群任意服务器上

####  测试

**1. 手动测试**

在logstash中安装multiline插件

```shell
./bin/logstash-plugin install file:///opt/model/logstash-6.2.3/logstash-filter-multiline-3.0.4.zip
```

后台运行收集异常信息的配置文件

```shell
nohup ./bin/logstash -f ./conf/fewfile.conf >./runlog/run.log &
```

在服务器上运行Spring Boot工程

```shell
java -jar ./SparkSubmit-0.0.1-SNAPSHOT.jar
```

在logstash监测文件中添加数据

```shell
cd /opt/model/logfile/spark/
vim aa.log
echo "ERRORgsafety1">>./aa.log
```

在elasticsearch页面中可以看到添加了一个新的索引

  ![wps13.jpg](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrciz0qpwj20fe05zdhs.jpg)

点击下图中的单次执行

 ![wps14.jpg](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrcjffazmj20fe06ht9n.jpg)

如果过去的1分钟内有报警信息，就会在企业微信可以收到报警的信息。如果没有报警信息，手动执行的时候就会出现 Watchers: no data was found that match the used "script" conditions

**2. 自动测试**

 ![wps15.jpg](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrcjsuv27j20fe06amya.jpg)

然后往日志里面添加异常信息，等过一分钟，就会在企业微信中看到报警信息。

### 4.5 定时删除Elastcisearch索引

#### 4.5.1 按月定时删除异常索引

```shell
#!/bin/bash

#当前日期
time=`date`

for ((i=1;i<=1;i++))
do
#指定日期
DATA=`date -d "$i month ago" +%Y.%m`

#删除一个月前的日志
curl -XDELETE http://10.3.10.231:9200/runlog-`date -d "$i month ago" +%Y.%m`

done
```

#### 4.5.2 按天定时删除异常索引

```shell
#当前日期
time=`date`

for ((i=1;i<=1;i++))
do
#指定日期
DATA=`date -d "$i day ago" +%Y.%m.%d`

#删除一天前的日志
curl -XDELETE http://10.3.10.231:9200/watcher_alarms-`date -d "$i day ago" +%Y.%m.%d`

done
```

#### 4.5.3 创建定时任务

crontab -e

```shell
* * 1 * *
 nohup /opt/model/crontabDeleteIndex/deleteIndexByMonth.sh>/opt/model/crontabDeleteIndex/
deleteIndexByMonth.log &
* 7 * * *
 nohup /opt/model/crontabDeleteIndex/deleteIndexByDay.sh>/opt/model/crontabDeleteIndex/
deleteIndexByDay.sh.log &
```



## 5. ELK集群测试

### 5.1 集群配件分布

| 集群地址      | 角色                    |
| ------------- | ----------------------- |
| 10.100.111.62 | elasticsearch /logstash |
| 10.100.111.63 | elasticsearch/kibana    |
| 10.100.111.64 | elasticsearch           |

### 5.2 集群说明

集群所在的用户名和用户组：search:search      其用户对应的密码：ser123456

* elasticsearch集群的访问：http://ip:9200

* kibana访问地址：http://ip:5601

es集群查看状态：

* ``` curl -XGET 'http://IP:9200/_cat/nodes?v&pretty' ```（查看集群节点）

* ```curl '10.100.111.64:9200/_cat/indices?v' ```   （查看索引）

elasticsearch的配置文件：`/usr/elasticsearch-6.2.3/config/ elasticsearch.yml`

> 注意点：elasticsearch集群必须在非root用户下使用。

### 5.3 测试用例

#### 5.3.1 输入为文件

```shell
[root@node111a62 logstash-6.2.4]# bin/logstash -f /usr/logstash6.2.4/conf.d/txtInput.conf

input{
    file {
        path => "/usr/logstash-6.2.4/logs/logstash-plain.log"
        start_position => "beginning"
}
}

output {
    elasticsearch {
        hosts => ["10.100.111.64:9200"]
        index => "logstash-log-%{+YYYY.MM.dd}"
}
}
```

#### 5.3.2 输入为kafka集群

```shell

input {
    kafka  {
      topics => ["CLLSEN-LIFELINE-HF-LOG"]
      bootstrap_servers => ["10.5.4.150:9092"]     
      group_id => "logstash-g1"
    }
}

output {
    elasticsearch{
        hosts => ["10.5.4.149:9200"]
        index => "kafka-%{+YYYY.MM.dd}"
}
}
```

#### 5.3.3 输入为redis数据库

```shell
[root@node111a62 logstash-6.2.4]# bin/logstash -f /usr/logstash-6.2.4/conf.d/redisInput.conf

input {
       redis {
          host => "10.5.4.112"
          port => "6379"
          db => "0"
          data_type => "list"
          key => "redis-log"
}
}

output {
    elasticsearch{
        hosts => ["10.100.111.64:9200"]
        index => "redis-%{+YYYY.MM.dd}"
}
}
```

## 6. 问题总结

**<font color='red'>6.1 权限问题</font>**

![1568623689998.png](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrcm4heesj20la04kweq.jpg)

解决方法：

1、查看当前用户及用户组：

```shell
groups 用户名
```

2、升级权限：

```shell
chown -R elk1:elk1 /usr/elasticsearch-6.2.3/
```

 **<font color='red'>6.2 主机地址映射错误问题</font>**

 ![1568624270351.png](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrcmpdh2wj20fv030748.jpg)

解决方法：

1、切换到 elasticsearch-head-master安装目录下，并执行

```shell
vim Gruntfile.js
```

2、将下面的hostname改成主机IP即可

![1568625609887.png](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrcnfvw1nj20m90b3q2z.jpg)

 **<font color='red'>6.3 kafka集成问题错误</font>**

![1568702343189.png](http://ww1.sinaimg.cn/large/b2f04ec3ly1gbrco3gl14j216101pwei.jpg)

修改本地主机名文件

```sh
vi /etc/hosts/
```

添加对应的IP地址以及主机名即可

